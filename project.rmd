
```{r setup, include=FALSE}
# Load required packages
library(ggplot2)
library(corrplot)
library(ggrepel)
library(gridExtra)
library(MASS)
library(Hotelling)
library(factoextra)
library(FactoMineR)
library(reshape2)
```

```{r}
library(dplyr)
# Load your dataset
df <- read.csv("~/Downloads/champs_and_runner_ups_series_averages.csv")

# Filter only Champions
champions <- subset(df, Status == "Champion")

# Add 3P% safely
champions$TP_Percent <- with(champions, ifelse(TPA > 0, TP / TPA * 100, NA))

# Create a label column
champions$Label <- paste(champions$Team, champions$Year)

# Identify notable teams
low_3pt <- subset(champions, TP < quantile(champions$TP, 0.05) & TPA < quantile(champions$TPA, 0.05))
high_3pt <- subset(champions, TP > quantile(champions$TP, 0.95) & TPA > quantile(champions$TPA, 0.95))

# Combine for labeling
notable <- rbind(low_3pt, high_3pt)

Plot
plot(1:10, 1:10, pch=2, col="red")
ggplot(champions, aes(x = TPA, y = TP)) +
  geom_point(color = "steelblue", size = 3)
  geom_text_repel(data = notable, aes(label = Label), size = 3, color = "black") +
  labs(title = "3-Point Shooting of NBA Champions",
       x = "3-Point Attempts per Game",
       y = "3-Point Makes per Game") +
  theme_minimal()


# Data preprocessing
df <- df %>%
  #select(-X) %>%
  mutate(
    FG_Percent = (FG / FGA) * 100,
    TP_Percent = ifelse(TPA > 0, (TP / TPA) * 100, 0),
    FT_Percent = ifelse(FTA > 0, (FT / FTA) * 100, 0),
    Offensive_Rating = PTS / FGA,
    Turnover_Rate = TOV / (FGA + 0.44 * FTA + TOV),
    Champion = ifelse(Status == "Champion", 1, 0)
  )

# Select key variables for analysis
analysis_vars <- c("PTS", "FG", "FGA", "TP", "TPA", "FT", "FTA", 
                   "ORB", "DRB", "TRB", "AST", "STL", "BLK", "TOV", "PF",
                   "FG_Percent", "TP_Percent", "FT_Percent")

# Select key variables for analysis
analysis_vars <- c("PTS", "FG", "FGA", "TP", "TPA", "FT", "FTA", 
                   "ORB", "DRB", "TRB", "AST", "STL", "BLK", "TOV", "PF",
                   "FG_Percent", "TP_Percent", "FT_Percent")
```

```{r}
# =============================================
# 1. EXPLORATORY DATA ANALYSIS
# =============================================

# Summary statistics by status
print("=== Summary Statistics by Status ===")
summary_stats <- df %>%
  group_by(Status) %>%
  summarise_at(vars(analysis_vars), list(mean = mean, sd = sd), na.rm = TRUE)
print(summary_stats)

# Correlation matrix
cor_matrix <- cor(df[analysis_vars], use = "complete.obs")

# Correlation heatmap
png("correlation_heatmap.png", width = 12, height = 10, units = "in", res = 300)
corrplot(cor_matrix, method = "color", type = "upper", 
         order = "hclust", tl.cex = 0.8, tl.col = "black")
dev.off()

# Box plots for key variables
create_boxplot <- function(var_name) {
  ggplot(df, aes(x = Status, y = get(var_name), fill = Status)) +
    geom_boxplot(alpha = 0.7) +
    geom_jitter(width = 0.2, alpha = 0.5) +
    labs(title = paste("Distribution of", var_name, "by Status"),
         y = var_name, x = "Status") +
    theme_minimal() +
    scale_fill_manual(values = c("Champion" = "gold", "Runner Up" = "lightblue"))
}

# Create box plots for key variables
key_vars <- c("PTS", "TP", "TPA", "STL", "BLK", "TOV", "AST")
plot_list <- lapply(key_vars, create_boxplot)

# Arrange plots
png("boxplots_comparison.png", width = 15, height = 12, units = "in", res = 300)
do.call(grid.arrange, c(plot_list, ncol = 3))
dev.off()

```

```{r}

# =============================================
# 2. HOTELLING'S T-TEST
# =============================================

print("=== Hotelling's T-Test Analysis ===")

Hotelling.T2.2sample=function(X, Y){
n=dim(X)[1]; m=dim(Y)[1]; p=dim(X)[2]
if(p!= dim(Y)[2]) return("Error: the dimensions of X and Y are not the same")
X.bar=colMeans(X); Y.bar=colMeans(Y)
X.S=cov(X); Y.S=cov(Y)
pooled.S=((n-1)*X.S+(m-1)*Y.S)/(m+n-2)
T2=t(X.bar-Y.bar)%*%solve((1/n+1/m)*pooled.S)%*%(X.bar-Y.bar)
p.value=1-pf(T2/((n+m-2)*p/(n+m-1-p)),p,n+m-1-p)
return(list(X.bar=X.bar, Y.bar=Y.bar, T2=T2, p.value=p.value))}

df1 <- read.csv("~/Downloads/champs_series_averages.csv")
df2 <- read.csv("~/Downloads/runner_ups_series_averages.csv")

champs_numeric <- df1[, -(1:4)]
champs_matrix <- as.matrix(champs_numeric)

runners_numeric <- df2[, -(1:4)]
runners_matrix <- as.matrix(runners_numeric)

cols_to_keep <- c("PTS", "TP", "FT", "ORB", "DRB", "AST", "STL", "BLK", "TOV")

champs_sub <- champs_numeric[, cols_to_keep]
runners_sub <- runners_numeric[, cols_to_keep]

champs_matrix <- as.matrix(champs_sub)
runners_matrix <- as.matrix(runners_sub)

Hotelling.T2.2sample(champs_matrix, runners_matrix)
```

```{r}

# =============================================
# 3. PRINCIPAL COMPONENT ANALYSIS (PCA)
# =============================================

print("=== Principal Component Analysis ===")

# Prepare data for PCA (standardize variables)
pca_data <- df[complete.cases(df[analysis_vars]), analysis_vars]
pca_data_scaled <- scale(pca_data)

# Perform PCA
pca_result <- PCA(pca_data_scaled, graph = FALSE)

# Print PCA summary
print(summary(pca_result))

# Scree plot
png("pca_scree_plot.png", width = 10, height = 6, units = "in", res = 300)
fviz_eig(pca_result, addlabels = TRUE, ylim = c(0, 30))
dev.off()

# Biplot
png("pca_biplot.png", width = 12, height = 10, units = "in", res = 300)
fviz_pca_biplot(pca_result, 
                col.ind = df[complete.cases(df[analysis_vars]), "Status"],
                palette = c("gold", "lightblue"),
                addEllipses = TRUE,
                label = "var",
                col.var = "black",
                repel = TRUE)
dev.off()

# Variable contributions to PC1 and PC2
print("=== Variable Contributions to Principal Components ===")
var_contrib <- pca_result$var$contrib
print("Top contributors to PC1:")
print(sort(var_contrib[,1], decreasing = TRUE)[1:8])
print("Top contributors to PC2:")
print(sort(var_contrib[,2], decreasing = TRUE)[1:8])

```

```{r}
# =============================================
# 4. LINEAR DISCRIMINANT ANALYSIS (LDA)
# =============================================

print("=== Linear Discriminant Analysis ===")

# Prepare data for LDA
lda_data <- df[complete.cases(df[c(analysis_vars, "Status")]), c(analysis_vars, "Status")]

# Perform LDA
lda_result <- lda(Status ~ ., data = lda_data[, c(analysis_vars, "Status")])
print(lda_result)

# LDA predictions
lda_pred <- predict(lda_result)

# Confusion matrix
confusion_matrix <- table(Actual = lda_data$Status, Predicted = lda_pred$class)
print("=== LDA Confusion Matrix ===")
print(confusion_matrix)

# Classification accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("LDA Classification Accuracy:", round(accuracy * 100, 2), "%"))

# Plot LDA results
lda_plot_data <- data.frame(
  LD1 = lda_pred$x[,1],
  Status = lda_data$Status,
  Team = df[complete.cases(df[c(analysis_vars, "Status")]), "Team"],
  Year = df[complete.cases(df[c(analysis_vars, "Status")]), "Year"]
)

png("lda_plot.png", width = 12, height = 8, units = "in", res = 300)
ggplot(lda_plot_data, aes(x = LD1, y = 0, color = Status)) +
  geom_point(size = 3, alpha = 0.7) +
  geom_density(aes(y = ..density..), alpha = 0.3) +
  labs(title = "Linear Discriminant Analysis Results",
       x = "Linear Discriminant 1",
       y = "Density") +
  scale_color_manual(values = c("Champion" = "black", "Runner Up" = "red")) +
  theme_minimal()
dev.off()

# Variable importance in LDA
print("=== LDA Coefficients (Variable Importance) ===")
lda_coeffs <- data.frame(
  Variable = names(lda_result$scaling[,1]),
  Coefficient = lda_result$scaling[,1]
)
lda_coeffs <- lda_coeffs[order(abs(lda_coeffs$Coefficient), decreasing = TRUE), ]
print(lda_coeffs)
```
```{r}
# =============================================
# MANOVA: Basketball Statistics Across Eras
# =============================================

# Load required libraries
library(ggplot2)
library(car)       # For MANOVA functions
library(broom)     # For tidy output

# Note: dplyr and data preprocessing already done in previous code

# =============================================
# 1. CREATE ERA VARIABLE
# =============================================
print("=== Creating Era Categories ===")

# Create era categories based on year
df <- df %>%
  mutate(Era = case_when(
    Year >= 1980 & Year <= 1989 ~ "1980s",
    Year >= 1990 & Year <= 1999 ~ "1990s", 
    Year >= 2000 & Year <= 2009 ~ "2000s",
    Year >= 2010 & Year <= 2019 ~ "2010s",
    Year >= 2020 ~ "2020s",
    TRUE ~ "Other"
  ))

# Convert Era to factor with proper ordering
df$Era <- factor(df$Era, levels = c("1980s", "1990s", "2000s", "2010s", "2020s"))

# Check era distribution
era_counts <- table(df$Era)
print("Teams per Era:")
print(era_counts)

# =============================================
# 2. SELECT VARIABLES FOR MANOVA
# =============================================
print("=== Selecting Variables for MANOVA ===")

# Remove highly correlated variables to avoid multicollinearity
# Keep either raw counts OR percentages, not both
manova_vars <- c("PTS", "TP", "FT", "ORB", "DRB", "AST", "STL", "BLK", "TOV")

# Alternative: Use only raw stats (uncomment if you prefer)
# manova_vars <- c("PTS", "FG", "FGA", "TP", "TPA", "FT", "FTA", 
#                  "ORB", "DRB", "TRB", "AST", "STL", "BLK", "TOV", "PF")

print(paste("Using", length(manova_vars), "variables for MANOVA:"))
print(manova_vars)

# Create complete cases dataset
manova_data <- df[complete.cases(df[c(manova_vars, "Era")]), c(manova_vars, "Era", "Year", "Team", "Status")]

print(paste("Complete cases for analysis:", nrow(manova_data)))
print("Final era distribution:")
print(table(manova_data$Era))

# Check for multicollinearity
print("=== Checking for Multicollinearity ===")
cor_matrix <- cor(manova_data[manova_vars], use = "complete.obs")
high_cor <- which(abs(cor_matrix) > 0.95 & cor_matrix != 1, arr.ind = TRUE)
if(nrow(high_cor) > 0) {
  print("High correlations found (>0.95):")
  for(i in 1:nrow(high_cor)) {
    var1 <- rownames(cor_matrix)[high_cor[i,1]]
    var2 <- colnames(cor_matrix)[high_cor[i,2]]
    correlation <- cor_matrix[high_cor[i,1], high_cor[i,2]]
    print(paste(var1, "vs", var2, ":", round(correlation, 3)))
  }
} else {
  print("No problematic multicollinearity detected")
}

# =============================================
# 3. PERFORM MANOVA TEST
# =============================================
print("=== MANOVA Analysis ===")

# Create the MANOVA model
manova_formula <- as.formula(paste("cbind(", paste(manova_vars, collapse = ", "), ") ~ Era"))
manova_result <- manova(manova_formula, data = manova_data)

# Print MANOVA results
print("MANOVA Results:")
print(summary(manova_result))

# Test assumptions - Multivariate normality (Box's M test)
print("=== Testing Assumptions ===")
if(require(heplots, quietly = TRUE)) {
  boxm_result <- boxM(manova_data[manova_vars], manova_data$Era)
  print("Box's M Test for Homogeneity of Covariance Matrices:")
  print(boxm_result)
} else {
  print("Install 'heplots' package for Box's M test")
}

# =============================================
# 4. FOLLOW-UP UNIVARIATE TESTS
# =============================================
print("=== Univariate ANOVA Follow-up Tests ===")

# If MANOVA is significant, perform univariate ANOVAs
manova_summary <- summary(manova_result)
if(manova_summary$stats[1,6] < 0.05) {  # Check p-value
  print("MANOVA is significant - performing univariate ANOVAs:")
  
  univariate_results <- data.frame(
    Variable = character(),
    F_statistic = numeric(),
    p_value = numeric(),
    Significant = logical(),
    stringsAsFactors = FALSE
  )
  
  for(var in manova_vars) {
    aov_formula <- as.formula(paste(var, "~ Era"))
    aov_result <- aov(aov_formula, data = manova_data)
    aov_summary <- summary(aov_result)
    
    f_stat <- aov_summary[[1]][1,4]
    p_val <- aov_summary[[1]][1,5]
    
    univariate_results <- rbind(univariate_results, data.frame(
      Variable = var,
      F_statistic = round(f_stat, 3),
      p_value = round(p_val, 4),
      Significant = p_val < 0.05
    ))
  }
  
  # Sort by significance
  univariate_results <- univariate_results[order(univariate_results$p_value), ]
  print(univariate_results)
  
  # =============================================
  # 5. POST-HOC ANALYSIS FOR SIGNIFICANT VARIABLES
  # =============================================
  print("=== Post-hoc Analysis (Tukey HSD) ===")
  
  significant_vars <- univariate_results$Variable[univariate_results$Significant]
  if(length(significant_vars) > 0) {
    for(var in significant_vars[1:min(5, length(significant_vars))]) {  # Limit to first 5 significant vars
      cat("\n--- Post-hoc for", var, "---\n")
      aov_model <- aov(as.formula(paste(var, "~ Era")), data = manova_data)
      tukey_result <- TukeyHSD(aov_model)
      print(tukey_result$Era)
    }
  }
} else {
  print("MANOVA is not significant - no follow-up tests needed")
}

# =============================================
# 6. DESCRIPTIVE STATISTICS BY ERA
# =============================================
print("=== Descriptive Statistics by Era ===")

# Calculate means by era for variables in the analysis
era_means <- manova_data %>%
  group_by(Era) %>%
  summarise(
    n = n(),
    PTS_mean = round(mean(PTS, na.rm = TRUE), 1),
    TP_mean = round(mean(TP, na.rm = TRUE), 1),
    FT_mean = round(mean(FT, na.rm = TRUE), 1),
    ORB_mean = round(mean(ORB, na.rm = TRUE), 1),
    DRB_mean = round(mean(DRB, na.rm = TRUE), 1),
    AST_mean = round(mean(AST, na.rm = TRUE), 1),
    STL_mean = round(mean(STL, na.rm = TRUE), 1),
    BLK_mean = round(mean(BLK, na.rm = TRUE), 1),
    TOV_mean = round(mean(TOV, na.rm = TRUE), 1),
    .groups = 'drop'
  )

print("Key Statistics by Era:")
print(era_means)

# =============================================
# 7. VISUALIZATION
# =============================================
print("=== Creating Visualizations ===")

# Plot showing evolution of key stats across eras
# Three-point shooting evolution
p1 <- ggplot(manova_data, aes(x = Era, y = TP, fill = Era)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Three-Point Shots Made Across Eras",
       x = "Era", y = "Three-Point Shots Made") +
  theme_minimal() +
  theme(legend.position = "none")

# Points evolution
p2 <- ggplot(manova_data, aes(x = Era, y = PTS, fill = Era)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Points Scored Across Eras",
       x = "Era", y = "Points") +
  theme_minimal() +
  theme(legend.position = "none")

# Save plots
png("era_threept_evolution.png", width = 10, height = 6, units = "in", res = 300)
print(p1)
dev.off()

png("era_points_evolution.png", width = 10, height = 6, units = "in", res = 300)
print(p2)
dev.off()

# =============================================
# 8. EFFECT SIZE CALCULATION
# =============================================
print("=== Effect Size (Eta-squared) ===")

if(exists("univariate_results") && nrow(univariate_results) > 0) {
  # Calculate eta-squared for significant variables
  eta_squared_results <- data.frame(
    Variable = character(),
    Eta_Squared = numeric(),
    Effect_Size = character(),
    stringsAsFactors = FALSE
  )
  
  for(var in significant_vars[1:min(5, length(significant_vars))]) {
    aov_model <- aov(as.formula(paste(var, "~ Era")), data = manova_data)
    ss_total <- sum(aov_model$model[,1]^2) - (sum(aov_model$model[,1])^2)/nrow(aov_model$model)
    ss_between <- sum(summary(aov_model)[[1]][1,2])
    eta_sq <- ss_between / ss_total
    
    effect_size <- ifelse(eta_sq < 0.01, "Small", 
                         ifelse(eta_sq < 0.06, "Medium", "Large"))
    
    eta_squared_results <- rbind(eta_squared_results, data.frame(
      Variable = var,
      Eta_Squared = round(eta_sq, 4),
      Effect_Size = effect_size
    ))
  }
  
  print("Effect Sizes for Significant Variables:")
  print(eta_squared_results)
}

print("=== MANOVA Analysis Complete ===")
```

```{r}
# =============================================
# 5. SUMMARY AND INSIGHTS
# =============================================

print("=== KEY FINDINGS SUMMARY ===")

# Most discriminating variables from t-tests
#top_discriminators <- head(t_test_results, 5)
print("Top 5 variables that differentiate Champions from Runner-ups:")
print(top_discriminators[, c("Variable", "p_value", "Difference")])

# PCA insights
print(paste("PC1 explains", round(pca_result$eig[1,2], 1), "% of variance"))
print(paste("PC2 explains", round(pca_result$eig[2,2], 1), "% of variance"))

# Create a final summary plot
png("championship_factors_summary.png", width = 15, height = 10, units = "in", res = 300)

# Subplot 1: Most important variables (from t-tests)
p1 <- ggplot(head(t_test_results, 8), aes(x = reorder(Variable, abs(Difference)), y = Difference)) +
  geom_col(fill = "steelblue", alpha = 0.7) +
  coord_flip() +
  labs(title = "Mean Differences: Champions vs Runner-ups",
       x = "Variable", y = "Difference (Champions - Runner-ups)") +
  theme_minimal()

# Subplot 2: PCA variable loadings
pc1_loadings <- data.frame(
  Variable = rownames(pca_result$var$coord),
  PC1_Loading = pca_result$var$coord[,1]
)
pc1_loadings <- pc1_loadings[order(abs(pc1_loadings$PC1_Loading), decreasing = TRUE), ]

p2 <- ggplot(head(pc1_loadings, 8), aes(x = reorder(Variable, abs(PC1_Loading)), y = PC1_Loading)) +
  geom_col(fill = "darkgreen", alpha = 0.7) +
  coord_flip() +
  labs(title = "PC1 Variable Loadings",
       x = "Variable", y = "PC1 Loading") +
  theme_minimal()

grid.arrange(p1, p2, ncol = 2)
dev.off()

print("Analysis complete! Check the generated PNG files for visualizations.")

```